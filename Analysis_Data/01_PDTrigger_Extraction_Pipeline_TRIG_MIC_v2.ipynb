{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis Pipeline for Intracranial Data\n",
    "\n",
    "\n",
    "## STEPS:\n",
    "##### 1. run the IMPORT AND LOAD DATA section.\n",
    "\n",
    "##### 2. fill in the values extracted from the plot from step 1 for following variables:\n",
    "\n",
    "\n",
    "Let's go"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting EDF parameters from /Volumes/GoogleDrive/My Drive/EEG_DATA_PIERRE/PAT_3390/PAT_3390_EEG_860617_languageMapping.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import mne\n",
    "from mne.utils import _TempDir\n",
    "import matplotlib.pyplot as plt\n",
    "import pyqtgraph as pg\n",
    "import pyqtgraph as plotWidget\n",
    "from get_trigger_indexes_photodiode import normalized\n",
    "%matplotlib qt\n",
    "from pd_parser.parse_pd import _read_raw, _to_tsv\n",
    "import time\n",
    "from get_trigger_indexes_photodiode import get_trigger_indexes_photodiode\n",
    "from datetime import datetime\n",
    "import read_trc\n",
    "import struct\n",
    "%matplotlib qt\n",
    "\n",
    "\n",
    "# def read_f(f, fmt):\n",
    "#     return struct.unpack(fmt, f.read(struct.calcsize(fmt)))\n",
    "\n",
    "### DEFINE PATHS\n",
    "Exper = '_FLM_'\n",
    "PT_id = 'PAT_3390'\n",
    "data_path = '/Volumes/GoogleDrive/My Drive/EEG_DATA_PIERRE/PAT_3390'\n",
    "# DEFINE NAMES\n",
    "# PT_id = \n",
    "\n",
    "# print(PT_id)\n",
    "script_path = '/Volumes/GoogleDrive/My Drive/EEG_DATA_PIERRE/Scripts'\n",
    "filename_edf = 'PAT_3390_EEG_860617_languageMapping.edf'\n",
    "data_raw_file = os.path.join(data_path, filename_edf)\n",
    "# data_raw_file = os.path.join(data_path, 'EEG_1051662_test_AudCatLoc_latency_w_microphone.edf')\n",
    "# data_raw_file_trc = os.path.join(data_path, PT_id,'PAT_3066_EEG_708977_Anon_CategoryLocalizer.TRC')\n",
    "### DEFINE PATHS ENDS\n",
    "\n",
    "fig = plt.figure(figsize=(100, 2))\n",
    "# DEFINE NAMES ENDS\n",
    "\n",
    "# LOAD TRIGGER and MIC DATA \n",
    "# data_raw_file = os.path.join(data_path, 'PAT_3066_EEG_708977_Anon_CategoryLocalizer.edf') #PAT_3066_EEG_695997_Anon_FLM.edf\n",
    "# trigger_ch = mne.io.read_raw_edf(data_raw_file,exclude=['ECG+','ECG-','MKR4+','Xe2', 'Xe3', 'Xe4', 'Xe5', 'Xe6'])\n",
    "trigger_ch = mne.io.read_raw_edf(data_raw_file,exclude=['ECG+','ECG-'])\n",
    "# sf, data, chan, n, start_time = read_trc.read_trc(data_raw_file_trc);\n",
    "# trigger_ch = struct.unpack('Xe1', data.read(struct.calcsize('Xe1')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract the PD Trigger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "*****----------------   MIC and Trig Test   ----------------*****\n",
      "\n",
      "*   Data location.... : /var/folders/85/ct7qgj4500s62pw9zxkv_xc40000gn/T/tmp_mne_tempdir_y79tq1j7\n",
      "\n",
      "\n",
      "Extracting EDF parameters from /Volumes/GoogleDrive/My Drive/EEG_DATA_PIERRE/PAT_3390/PAT_3390_EEG_860617_languageMapping.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "channels:  ['FOG1', 'FOG2', 'FOG3', 'FOG4', 'FOG5', 'FOG6', 'FOG7', 'FOG8', 'FOG9', 'FOG10', 'FOG11', 'FOG12', 'IAG1', 'IAG2', 'IAG3', 'IAG4', 'IAG5', 'IAG6', 'IAG7', 'IAG8', 'IAG9', 'IAG10', 'IAG11', 'IAG12', 'IAG13', 'IAG14', 'IAG15', 'IAG16', 'IAG17', 'IAG18', 'CAG1', 'CAG2', 'CAG3', 'CAG4', 'CAG5', 'CAG6', 'CAG7', 'CAG8', 'CAG9', 'CAG10', 'CAG11', 'CAG12', 'CPG1', 'CPG2', 'CPG3', 'CPG4', 'CPG5', 'CPG6', 'CPG7', 'CPG8', 'CPG9', 'CPG10', 'CPG11', 'CPG12', 'CPG13', 'CPG14', 'CPG15', 'EX1', 'EX2', 'EX3', 'EX4', 'EX5', 'EX6', 'EX7', 'MKR1+', 'TPG1', 'TPG2', 'TPG3', 'TPG4', 'TPG5', 'AG1', 'AG2', 'AG3', 'AG4', 'AG5', 'AG6', 'AG7', 'AG8', 'AG9', 'AG10', 'AG11', 'AG12', 'HAG1', 'HAG2', 'HAG3', 'HAG4', 'HAG5', 'HAG6', 'HAG7', 'HAG8', 'HAG9', 'HAG10', 'HAG11', 'HAG12', 'HPG1', 'HPG2', 'HPG3', 'HPG4', 'HPG5', 'HPG6', 'HPG7', 'HPG8', 'HPG9', 'HPG10', 'PHG1', 'PHG2', 'PHG3', 'PHG4', 'PHG5', 'PHG6', 'PHG7', 'PHG8', 'PHG9', 'PHG10', 'PHG11', 'PHG12', 'TOL1', 'TOL2', 'TOL3', 'TOL4', 'TOL5', 'TOL6', 'TOL7', 'TOL8', 'TOL9', 'TOL10', 'ECG+', 'ECG-', 'PHOTO', 'MKR2+']\n",
      "440000 (440000,)\n",
      "*   length of onset indexes:  49\n",
      "*   length of offset indexes:  51\n",
      "*   length of Time & Trigger:  440000   440000\n"
     ]
    }
   ],
   "source": [
    "# GET PHOTODIODE TRIGGERS\n",
    "Exper = ' FLM '\n",
    "print('\\n\\n*****----------------  ',Exper,'  ----------------*****\\n' )\n",
    "\n",
    "trig_chan_name = 'PHOTO'\n",
    "t_onset_s= 400000\n",
    "t_offset_s= 840000\n",
    "index_onset,index_offset , trigger_ch_new,_ = get_trigger_indexes_photodiode(data_raw_file = data_raw_file, data_path=data_path,t_start= t_onset_s, t_end=t_offset_s,threshold_val=0.76, trigger_channel=trig_chan_name)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SAVE DATA:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "date_txt=str(datetime.date(datetime.now()))\n",
    "name_txt = PT_id +Exper+'_triggerPD_' + date_txt+'.txt'\n",
    "with open(os.path.join(data_path,name_txt ), \"w\") as textfile:\n",
    "    textfile.write('onsets;offsets\\n')\n",
    "    XY = [i for i in zip(index_onset, index_offset)]\n",
    "    for x, y in XY:\n",
    "        textfile.write(str(x)+';'+str(y))\n",
    "        textfile.write('\\n')\n",
    "    textfile.close()\n",
    "\n",
    "#     # 28840\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### VALIDATION\n",
    "Assert that the trigger onset and offset are a pair and the onset is before the offset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# VALIDATION\n",
    "# index_on_true=index_onset\n",
    "# index_off_true=index_offset\n",
    "# index_onset = list(index_onset)\n",
    "# index_offset = list(index_offset)\n",
    "# validity = [] # 0 for invalid, 1 for valid\n",
    "# for i in range(min([len(index_on_true),len(index_off_true)])):\n",
    "#     tempe=True\n",
    "#     # print(i)\n",
    "#     # if i >= min([len(index_on_true),len(index_off_true)]):\n",
    "#     #     validity.append(0)\n",
    "#     if index_onset[i] < index_offset[i]:\n",
    "#         while tempe:\n",
    "#             while index_onset[i] < index_offset[i]:\n",
    "#                 if index_onset[i+1] <index_offset[i]:\n",
    "#                     # print(index_onset[i])\n",
    "#                     index_onset.pop(i)\n",
    "#                     validity.append(0)\n",
    "#                     tempe=False\n",
    "#                     break\n",
    "#                 else:\n",
    "#                     validity.append(1)\n",
    "#                     tempe=False\n",
    "#                     break\n",
    "#     else:\n",
    "#         while tempe:\n",
    "#             while index_onset[i] > index_offset[i]:\n",
    "#                 if index_onset[i+1] >index_offset[i]:\n",
    "#                     index_offset.pop(i)\n",
    "#                     validity.append(0)\n",
    "#                     tempte=False\n",
    "#                 else:\n",
    "#                     validity.append(1)\n",
    "#                     tempe=False\n",
    "#                     break\n",
    "\n",
    "\n",
    "\n",
    "# if len(index_offset)!=len(index_onset):\n",
    "#     if len(index_offset)>len(index_onset):\n",
    "#         index_onset.append(0)\n",
    "# diff_oo=[index_offset[i]-index_onset[i] for i in range(len(index_offset))]\n",
    "# assert np.min(diff_oo)>=0\n",
    "# # print(validity, len(validity),len(index_onset),len(index_offset))\n",
    "# validity=np.array(validity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2181120,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<pyqtgraph.graphicsItems.PlotDataItem.PlotDataItem at 0x7fa5756755f0>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# VISUALIZE\n",
    "fig = plt.figure(figsize=(100, 2))\n",
    "print(np.shape(trigger_ch2))\n",
    "import pyqtgraph as pg\n",
    "import pyqtgraph as plotWidget\n",
    "# pg.plot(time_s,trigger_ch2)\n",
    "# pg.plot(time_s,index_onset)\n",
    "# plt.close(fig)\n",
    "time_s = np.linspace(0,len(trigger_ch2),num=len(trigger_ch2))\n",
    "plotWidget = pg.plot(title=\"Validation of Triggers PD: x is onset, o is offset\")\n",
    "plotWidget.plot(time_s,trigger_ch2)\n",
    "plotWidget.plot(index_offset,trigger_ch2[index_offset],pen=None, symbol='o')\n",
    "plotWidget.plot(index_onset,trigger_ch2[index_onset],pen=None, symbol='x')\n",
    "# plotWidget.plot(index_onset[validity==False],trigger_ch2[index_onset[validity==False]],pen=None, symbol='x')\n",
    "\n",
    "# plotWidget.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save The Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "date_txt=str(datetime.date(datetime.now()))\n",
    "name_txt = PT_id +Exper+'_triggerPD_' + date_txt+'.txt'\n",
    "with open(os.path.join(data_path,name_txt ), \"w\") as textfile:\n",
    "    textfile.write('onsets;offsets\\n')\n",
    "    XY = [i for i in zip(index_onset, index_offset)]\n",
    "    for x, y in XY:\n",
    "        textfile.write(str(x)+';'+str(y))\n",
    "        textfile.write('\\n')\n",
    "    textfile.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FINISHED HERE: \n",
    "##### Everything below is draft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "## CHECKS ALL CHANNELS\n",
    "# for ch_nam in trigger_ch.info.ch_names:\n",
    "#     picks = mne.pick_channels_regexp(trigger_ch.info.ch_names, regexp=ch_nam) \n",
    "#     trigger_ch2 = trigger_ch.get_data(picks=picks)\n",
    "#     trigger_ch2 = trigger_ch2[0].T\n",
    "#     time_s = np.linspace(0,len(trigger_ch2),num=len(trigger_ch2))\n",
    "\n",
    "#     # VISUALIZE\n",
    "#     # fig = plt.figure(figsize=(100, 2))\n",
    "#     print(np.shape(trigger_ch2))\n",
    "#     import pyqtgraph as pg\n",
    "#     pg.plot(time_s,trigger_ch2,title=ch_nam)\n",
    "#     pg.parametertree\n",
    "## CHECKS ALL CHANNELS ENDS\n",
    "\n",
    "\n",
    "#     # 30446\n",
    "# # index_on_true=index_onset\n",
    "# # index_off_true=index_offset\n",
    "\n",
    "# Exper = 'FLM_audio'\n",
    "# print('\\n\\n*****----------------',Exper,'  ----------------*****\\n' )\n",
    "# t_onset_s= 1325000\n",
    "# t_offset_s= 2130000\n",
    "# index_onset,index_offset , trigger_ch_new,_ = get_trigger_indexes_photodiode(data_raw_file = data_raw_file, data_path=data_path,t_start= t_onset_s, t_end=t_offset_s,threshold_val=0.72)\n",
    "\n",
    "# date_txt=str(datetime.date(datetime.now()))\n",
    "# name_txt = PT_id +Exper+'_triggerPD_' + date_txt+'.txt'\n",
    "# with open(os.path.join(data_path,name_txt ), \"w\") as textfile:\n",
    "#     textfile.write('onsets;offsets\\n')\n",
    "#     XY = [i for i in zip(index_onset, index_offset)]\n",
    "#     for x, y in XY:\n",
    "#         textfile.write(str(x)+';'+str(y))\n",
    "#         textfile.write('\\n')\n",
    "#     textfile.close()\n",
    "\n",
    "    # 28840\n",
    "    # 30446\n",
    "# index_on_true=index_onset\n",
    "# index_off_true=index_offset\n",
    "\n",
    "\n",
    "\n",
    "# Exper = 'FLM_reading'\n",
    "# print('\\n\\n*****----------------',Exper,'  ----------------*****\\n' )\n",
    "# t_onset_s= 2702000\n",
    "# t_offset_s= 3315000\n",
    "# index_onset,index_offset , trigger_ch_new,_ = get_trigger_indexes_photodiode(data_raw_file = data_raw_file, data_path=data_path,t_start= t_onset_s, t_end=t_offset_s,threshold_val=0.75)\n",
    "\n",
    "# date_txt=str(datetime.date(datetime.now()))\n",
    "# name_txt = PT_id +Exper+'_triggerPD_' + date_txt+'.txt'\n",
    "# with open(os.path.join(data_path,name_txt ), \"w\") as textfile:\n",
    "#     textfile.write('onsets;offsets\\n')\n",
    "#     XY = [i for i in zip(index_onset, index_offset)]\n",
    "#     for x, y in XY:\n",
    "#         textfile.write(str(x)+';'+str(y))\n",
    "#         textfile.write('\\n')\n",
    "#     textfile.close()\n",
    "\n",
    "    # 28840\n",
    "    # 30446\n",
    "# index_on_true=index_onset\n",
    "# index_off_true=index_offset\n",
    "# t_onset_s= 1022000\n",
    "# t_offset_s= 1900000\n",
    "# index_onset,index_offset , trigger_ch_new,_ = get_trigger_indexes_photodiode(data_raw_file = data_raw_file, data_path=data_path,t_start= t_onset_s, t_end=t_offset_s,threshold_val=0.75)\n",
    "\n",
    "# index_on_true=index_onset\n",
    "# index_off_true=index_offset\n",
    "\n",
    "# t_onset_s= 1022000\n",
    "# t_offset_s= 1900000\n",
    "# index_onset,index_offset , trigger_ch_new,_ = get_trigger_indexes_photodiode(data_raw_file = data_raw_file, data_path=data_path,t_start= t_onset_s, t_end=t_offset_s,threshold_val=0.75)\n",
    "\n",
    "# index_on_true=index_onset\n",
    "# index_off_true=index_offset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
  },
  "kernelspec": {
   "display_name": "Python 3.7.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
