{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis Pipeline for Intracranial Data\n",
    "\n",
    "\n",
    "## STEPS:\n",
    "##### 1. run the IMPORT AND LOAD DATA section.\n",
    "\n",
    "##### 2. fill in the values extracted from the plot from step 1 for following variables:\n",
    "\n",
    "\n",
    "Let's go"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "*****----------------   FLM_reading   ----------------*****\n",
      "\n",
      "*   Data location.... : /var/folders/85/ct7qgj4500s62pw9zxkv_xc40000gn/T/tmp_mne_tempdir_shtz7gs2\n",
      "\n",
      "\n",
      "/Users/lorafanda/Documents/Coding/Experiments_PsychoPy/Experiments_PsychoPy/Analysis_Data/PAT_2868/PAT_2868_EEG_908710_Anon_FLM+VCL.edf\n",
      "Extracting EDF parameters from /Users/lorafanda/Documents/Coding/Experiments_PsychoPy/Experiments_PsychoPy/Analysis_Data/PAT_2868/PAT_2868_EEG_908710_Anon_FLM+VCL.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "channels:  ['FOP1', 'FOP2', 'FOP3', 'FOP4', 'FOP5', 'IDM1', 'IDM2', 'IDM3', 'IDM4', 'IDM5', 'IDP1', 'IDP2', 'IDP3', 'IDP4', 'IDP5', 'SMA1', 'SMA2', 'SMA3', 'SMA4', 'SMA5', 'PRS1', 'PRS2', 'PRS3', 'PRS4', 'PRS5', 'PRI1', 'PRI2', 'PRI3', 'PRI4', 'PRI5', 'POS1', 'POS2', 'POS3', 'POS4', 'POS5', 'POS6', 'POS7', 'POS8', 'POM1', 'POM2', 'POM3', 'POM4', 'POM5', 'POI1', 'POI2', 'POI3', 'POI4', 'POI5', 'PPS1', 'PPS2', 'PPS3', 'PPS4', 'PPS5', 'PPI1', 'PPI2', 'PPI3', 'PPI4', 'PPI5', 'EX1', 'EX2', 'EX3', 'EX4', 'EX5', 'EX6', 'MKR1+', 'POP1', 'POP2', 'POP3', 'POP4', 'POP5', 'ECG+', 'ECG-', 'PHOTO', 'MKR2+']\n",
      "820000 (820000,)\n",
      "*   length of onset indexes:  50\n",
      "*   length of offset indexes:  50\n",
      "*   length of Time & Trigger:  820000   820000\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "# from mne.utils import _TempDir\n",
    "import matplotlib.pyplot as plt\n",
    "# import pyqtgraph as pg\n",
    "# import pyqtgraph as plotWidget\n",
    "# from get_trigger_indexes_photodiode import normalized\n",
    "%matplotlib qt\n",
    "# from pd_parser.parse_pd import _read_raw, _to_tsv\n",
    "import time\n",
    "from get_trigger_indexes_photodiode import get_trigger_indexes_photodiode\n",
    "from datetime import datetime\n",
    "import struct\n",
    "%matplotlib qt\n",
    "\n",
    "\n",
    "\n",
    "# DEFINE PATHS\n",
    "Exper = 'FLM_reading'\n",
    "PT_id = 'PAT_2868' #TODO\n",
    "# filename_edf = 'PAT_3975_EEG_1631437_FLM_anon.edf' #TODO\n",
    "# PREDEFINED PATHS\n",
    "# data_path = '/Volumes/GoogleDrive/My Drive/EEG_DATA_PIERRE'\n",
    "data_path_file = '/Users/lorafanda/Documents/Coding/Experiments_PsychoPy/Experiments_PsychoPy/Analysis_Data/PAT_2868/PAT_2868_EEG_908710_Anon_FLM+VCL.edf'\n",
    "data_path = '/Users/lorafanda/Documents/Coding/Experiments_PsychoPy/Experiments_PsychoPy/Analysis_Data/'\n",
    "# data_raw_file = os.path.join(data_path,PT_id, filename_edf)\n",
    "\n",
    "\n",
    "# LOAD TRIGGER DATA \n",
    "print('\\n\\n*****----------------  ',Exper,'  ----------------*****\\n' )\n",
    "fig = plt.figure(figsize=(100, 2))\n",
    "trig_chan_name = 'PHOTO'\n",
    "t_onset_s= 2230000\n",
    "t_offset_s= 3050000\n",
    "index_onset,index_offset , trigger_ch_new,_ = get_trigger_indexes_photodiode(data_raw_file = data_path_file, data_path=data_path,t_start= t_onset_s, t_end=t_offset_s,threshold_val=0.7, trigger_channel=trig_chan_name,skip_samples=50,flip_trigs=True)\n",
    "\n",
    "# FROM ABOVE PLOT, FILL THE TRIGGER ONSET OFFSETS PER EACH BLOCK\n",
    "t_onset_s1= 400000 #TODO\n",
    "t_offset_s1= 840000 #TODO\n",
    "t_onset_s2= 970000 #TODO\n",
    "t_offset_s2= 1680000 #TODO\n",
    "t_onset_s3= 1690000 #TODO\n",
    "t_offset_s3= 2500000 #TODO\n",
    "\n",
    "\n",
    "# print(['Data saved as: ' + name_txt])\n",
    "#     # 28840\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract the PD Trigger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting EDF parameters from /Users/lorafanda/Documents/Coding/Experiments_PsychoPy/Experiments_PsychoPy/Analysis_Data/PAT_2868/PAT_2868_EEG_908710_Anon_FLM+VCL.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "['Data saved as: PAT_2868FLM_reading_triggerPD_2023-08-11.tsv']\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# Exper = '_FLM_'\n",
    "import mne\n",
    "trigger_ch = mne.io.read_raw_edf(data_path_file,exclude=['ECG+','ECG-'])\n",
    "\n",
    "Exper = Exper\n",
    "date_txt=str(datetime.date(datetime.now()))\n",
    "name_txt = PT_id +Exper+'_triggerPD_' + date_txt+'.tsv'\n",
    "with open(os.path.join(data_path,name_txt ), \"w\") as textfile:\n",
    "    textfile.write('onset\\tonset_duration\\tsample\\tsample_offsets\\n')\n",
    "    XY = [i for i in zip(index_onset, index_offset)]\n",
    "    for x, y in XY:\n",
    "        textfile.write(str(x/trigger_ch.info['sfreq'])+'\\t'+str((y-x)/trigger_ch.info['sfreq']) + '\\t'+str(x) +'\\t'+str(y))\n",
    "        textfile.write('\\n')\n",
    "    textfile.close()\n",
    "\n",
    "print(['Data saved as: ' + name_txt])\n",
    "#     # 28840\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### VALIDATION\n",
    "Assert that the trigger onset and offset are a pair and the onset is before the offset"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# VALIDATION\n",
    "# index_on_true=index_onset\n",
    "# index_off_true=index_offset\n",
    "# index_onset = list(index_onset)\n",
    "# index_offset = list(index_offset)\n",
    "# validity = [] # 0 for invalid, 1 for valid\n",
    "# for i in range(min([len(index_on_true),len(index_off_true)])):\n",
    "#     tempe=True\n",
    "#     # print(i)\n",
    "#     # if i >= min([len(index_on_true),len(index_off_true)]):\n",
    "#     #     validity.append(0)\n",
    "#     if index_onset[i] < index_offset[i]:\n",
    "#         while tempe:\n",
    "#             while index_onset[i] < index_offset[i]:\n",
    "#                 if index_onset[i+1] <index_offset[i]:\n",
    "#                     # print(index_onset[i])\n",
    "#                     index_onset.pop(i)\n",
    "#                     validity.append(0)\n",
    "#                     tempe=False\n",
    "#                     break\n",
    "#                 else:\n",
    "#                     validity.append(1)\n",
    "#                     tempe=False\n",
    "#                     break\n",
    "#     else:\n",
    "#         while tempe:\n",
    "#             while index_onset[i] > index_offset[i]:\n",
    "#                 if index_onset[i+1] >index_offset[i]:\n",
    "#                     index_offset.pop(i)\n",
    "#                     validity.append(0)\n",
    "#                     tempte=False\n",
    "#                 else:\n",
    "#                     validity.append(1)\n",
    "#                     tempe=False\n",
    "#                     break\n",
    "\n",
    "\n",
    "\n",
    "# if len(index_offset)!=len(index_onset):\n",
    "#     if len(index_offset)>len(index_onset):\n",
    "#         index_onset.append(0)\n",
    "diff_oo=[index_offset[i]-index_onset[i] for i in range(len(index_offset))]\n",
    "assert np.min(diff_oo)>=0\n",
    "# print(validity, len(validity),len(index_onset),len(index_offset))\n",
    "# validity=np.array(validity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2181120,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<pyqtgraph.graphicsItems.PlotDataItem.PlotDataItem at 0x7fa5756755f0>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# VISUALIZE\n",
    "fig = plt.figure(figsize=(100, 2))\n",
    "print(np.shape(trigger_ch2))\n",
    "import pyqtgraph as pg\n",
    "import pyqtgraph as plotWidget\n",
    "# pg.plot(time_s,trigger_ch2)\n",
    "# pg.plot(time_s,index_onset)\n",
    "# plt.close(fig)\n",
    "time_s = np.linspace(0,len(trigger_ch2),num=len(trigger_ch2))\n",
    "plotWidget = pg.plot(title=\"Validation of Triggers PD: x is onset, o is offset\")\n",
    "plotWidget.plot(time_s,trigger_ch2)\n",
    "plotWidget.plot(index_offset,trigger_ch2[index_offset],pen=None, symbol='o')\n",
    "plotWidget.plot(index_onset,trigger_ch2[index_onset],pen=None, symbol='x')\n",
    "# plotWidget.plot(index_onset[validity==False],trigger_ch2[index_onset[validity==False]],pen=None, symbol='x')\n",
    "\n",
    "# plotWidget.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save The Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "date_txt=str(datetime.date(datetime.now()))\n",
    "name_txt = PT_id +Exper+'_triggerPD_' + date_txt+'.txt'\n",
    "with open(os.path.join(data_path,name_txt ), \"w\") as textfile:\n",
    "    textfile.write('onsets;offsets\\n')\n",
    "    XY = [i for i in zip(index_onset, index_offset)]\n",
    "    for x, y in XY:\n",
    "        textfile.write(str(x)+';'+str(y))\n",
    "        textfile.write('\\n')\n",
    "    textfile.close()\n",
    "\n",
    "    # 28840\n",
    "    # 30446"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FINISHED HERE: \n",
    "##### Everything below is draft"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
  },
  "kernelspec": {
   "display_name": "Python 3.7.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
