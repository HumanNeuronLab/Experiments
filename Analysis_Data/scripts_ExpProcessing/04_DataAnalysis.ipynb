{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Version 1 chatgpt structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "ieeg_data.txt not found.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/85/ct7qgj4500s62pw9zxkv_xc40000gn/T/ipykernel_3569/3236634496.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[0;31m# Example usage:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[0;31m# Load iEEG data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloadtxt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'ieeg_data.txt'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[0;31m# Step 1: Data Cleaning\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/numpy/lib/npyio.py\u001b[0m in \u001b[0;36mloadtxt\u001b[0;34m(fname, dtype, comments, delimiter, converters, skiprows, usecols, unpack, ndmin, encoding, max_rows, like)\u001b[0m\n\u001b[1;32m   1065\u001b[0m             \u001b[0mfname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos_fspath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1066\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0m_is_string_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1067\u001b[0;31m             \u001b[0mfh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_datasource\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rt'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1068\u001b[0m             \u001b[0mfencoding\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'encoding'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'latin1'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1069\u001b[0m             \u001b[0mfh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/numpy/lib/_datasource.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(path, mode, destpath, encoding, newline)\u001b[0m\n\u001b[1;32m    191\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    192\u001b[0m     \u001b[0mds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDataSource\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdestpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 193\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnewline\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnewline\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    194\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/numpy/lib/_datasource.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(self, path, mode, encoding, newline)\u001b[0m\n\u001b[1;32m    531\u001b[0m                                       encoding=encoding, newline=newline)\n\u001b[1;32m    532\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 533\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mIOError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"%s not found.\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    534\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    535\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mOSError\u001b[0m: ieeg_data.txt not found."
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import signal\n",
    "\n",
    "# Step 1: Data Cleaning\n",
    "def clean_data(signal, threshold):\n",
    "    # Apply artifact rejection based on thresholding\n",
    "    cleaned_signal = np.copy(signal)\n",
    "    cleaned_signal[np.abs(signal) > threshold] = np.nan\n",
    "    return cleaned_signal\n",
    "\n",
    "# Step 2: Resampling\n",
    "def resample_data(signal, original_fs, target_fs):\n",
    "    resampled_signal = signal[::int(original_fs / target_fs)]\n",
    "    return resampled_signal, target_fs\n",
    "\n",
    "# Step 3: Referencing\n",
    "def apply_reference(signal, reference_type):\n",
    "    if reference_type == 'CAR':\n",
    "        mean_signal = np.nanmean(signal, axis=1, keepdims=True)\n",
    "        referenced_signal = signal - mean_signal\n",
    "    elif reference_type == 'bipolar':\n",
    "        referenced_signal = np.diff(signal, axis=0)\n",
    "    else:\n",
    "        referenced_signal = signal  # No referencing\n",
    "    return referenced_signal\n",
    "\n",
    "# Step 4: Filtering\n",
    "def apply_bandpass_filter(signal, fs, lowcut, highcut):\n",
    "    b, a = signal.butter(4, [lowcut, highcut], btype='bandpass', fs=fs)\n",
    "    filtered_signal = signal.lfilter(b, a, signal)\n",
    "    return filtered_signal\n",
    "\n",
    "# Step 5: Segmentation\n",
    "def segment_data(signal, segment_length):\n",
    "    num_segments = int(len(signal) / segment_length)\n",
    "    segments = np.array_split(signal[:num_segments * segment_length], num_segments)\n",
    "    return segments\n",
    "\n",
    "# Step 6: Artifact Removal (optional)\n",
    "def remove_artifacts(signal, artifact_indices):\n",
    "    cleaned_signal = np.copy(signal)\n",
    "    cleaned_signal[artifact_indices] = np.nan\n",
    "    return cleaned_signal\n",
    "\n",
    "# Step 7: Normalization (optional)\n",
    "def normalize_data(signal):\n",
    "    normalized_signal = (signal - np.nanmean(signal)) / np.nanstd(signal)\n",
    "    return normalized_signal\n",
    "\n",
    "# Step 8: Feature Extraction (example)\n",
    "def extract_features(signal):\n",
    "    features = np.mean(signal, axis=1)  # Example: Compute the mean of each segment\n",
    "    return features\n",
    "\n",
    "# Example usage:\n",
    "# Load iEEG data\n",
    "data = np.loadtxt('ieeg_data.txt')\n",
    "\n",
    "# Step 1: Data Cleaning\n",
    "threshold = 100  # Adjust threshold based on the data characteristics\n",
    "cleaned_data = clean_data(data, threshold)\n",
    "\n",
    "# Visualize the cleaned data\n",
    "plt.plot(cleaned_data)\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Amplitude')\n",
    "plt.title('Cleaned Data')\n",
    "plt.show()\n",
    "\n",
    "# Step 2: Resampling\n",
    "original_fs = 1000  # Original sampling frequency in Hz\n",
    "target_fs = 250  # Target sampling frequency in Hz\n",
    "resampled_data, fs = resample_data(cleaned_data, original_fs, target_fs)\n",
    "\n",
    "# Visualize the resampled data\n",
    "plt.plot(resampled_data)\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Amplitude')\n",
    "plt.title('Resampled Data')\n",
    "plt.show()\n",
    "\n",
    "# Step 3: Referencing\n",
    "reference_type = 'CAR'  # Choose reference type: 'CAR', 'bipolar', or 'none'\n",
    "referenced_data = apply_reference(resampled_data, reference_type)\n",
    "\n",
    "# Visualize the referenced data\n",
    "plt.plot(referenced_data)\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Amplitude')\n",
    "plt.title('Referenced Data')\n",
    "plt.show()\n",
    "\n",
    "# Step 4: Filtering\n",
    "lowcut = 1  # Low-pass filter cutoff frequency in Hz\n",
    "highcut = 100  # High-pass filter cutoff frequency in Hz\n",
    "filtered_data = apply_bandpass_filter(referenced_data, fs, lowcut, highcut)\n",
    "\n",
    "# Visualize the filtered data\n",
    "plt.plot(filtered_data)\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Amplitude')\n",
    "plt.title('Filtered Data')\n",
    "plt.show()\n",
    "\n",
    "# Step 5: Segmentation\n",
    "segment_length = 5 * fs  # Segment length in seconds (example: 5 seconds)\n",
    "segments = segment_data(filtered_data, segment_length)\n",
    "\n",
    "# Visualize the segmented data\n",
    "for segment in segments:\n",
    "    plt.plot(segment)\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Amplitude')\n",
    "plt.title('Segmented Data')\n",
    "plt.show()\n",
    "\n",
    "# Step 6: Artifact Removal (optional)\n",
    "# artifact_indices = detect_artifacts(filtered_data)  # Identify artifact indices\n",
    "# cleaned_data = remove_artifacts(filtered_data, artifact_indices)\n",
    "\n",
    "# Step 7: Normalization (optional)\n",
    "# normalized_data = normalize_data(cleaned_data)\n",
    "\n",
    "# Step 8: Feature Extraction\n",
    "features = extract_features(segments)\n",
    "\n",
    "# Display the results\n",
    "plt.plot(features)\n",
    "plt.xlabel('Segment')\n",
    "plt.ylabel('Feature Value')\n",
    "plt.title('Extracted Features')\n",
    "plt.show()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## version 2 chatgpt code\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LOAD PARAMETERS\n",
    "\n",
    "# TODO: Response plots -2 to 2 seconds\n",
    "# Check preferences for parallelizing for speed (cap on memory)\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import mne\n",
    "from mne.time_frequency import tfr_morlet, tfr_multitaper\n",
    "\n",
    "data_dir = 'S:/HumanNeuronLab/DATARAW/PAT_3975'\n",
    "data_file = 'PAT_3975_EEG_1631437_FLM_anon.TRC'\n",
    "trig_file_imag = 'PAT_3975__FLM_picture__triggerPD_2023-04-27.tsv'\n",
    "trig_file_read = ''\n",
    "trig_file_audi = ''\n",
    "events_file = 'sub-PAT_3975_task-LanguageMapping_timestamp-30-3-2023(10h44m14s)_lang-GER_events.tsv'\n",
    "patient_number = '3975'\n",
    "\n",
    "# PREPROCESSING\n",
    "\n",
    "# read events file\n",
    "try:\n",
    "    evts = mne.read_events(os.path.join(data_dir, events_file), verbose=False)\n",
    "except FileNotFoundError:\n",
    "    evts = mne.read_events(os.path.join(data_dir, events_file), verbose=False, skiprows=4)\n",
    "\n",
    "# read iEEG file header and trigger information\n",
    "raw = mne.io.read_raw(os.path.join(data_dir, data_file), preload=True)\n",
    "\n",
    "# Read stimuli presented (onset) and response (offset) values from the photodiode file.\n",
    "trig_imag = np.loadtxt(os.path.join(data_dir, trig_file_imag), skiprows=1)\n",
    "trig_audi = np.loadtxt(os.path.join(data_dir, trig_file_audi), skiprows=1)\n",
    "trig_read = np.loadtxt(os.path.join(data_dir, trig_file_read), skiprows=1)\n",
    "# Combine all three categories\n",
    "trig = np.concatenate((np.column_stack((trig_imag, np.ones_like(trig_imag[:, 0]))),\n",
    "                       np.column_stack((trig_audi, np.ones_like(trig_audi[:, 0]) * 2)),\n",
    "                       np.column_stack((trig_read, np.ones_like(trig_read[:, 0]) * 3))))\n",
    "nTrl = trig.shape[0]\n",
    "\n",
    "# load iEEG data in memory with minimal preprocessing\n",
    "ch_names = raw.info['ch_names']\n",
    "cfg_preproc = dict(dataset=os.path.join(data_dir, data_file),\n",
    "                   tmin=trig[:, 2] - raw.info['sfreq'],\n",
    "                   tmax=trig[:, 3] + (3 * raw.info['sfreq']),\n",
    "                   baseline=(-0.25, 0),\n",
    "                   detrend=1,\n",
    "                   picks=np.arange(len(ch_names)),\n",
    "                   reject=None,\n",
    "                   preload=True)\n",
    "data = mne.io.read_raw_egi(**cfg_preproc)\n",
    "\n",
    "# define parameters for TF analysis\n",
    "cfg_timefreq = dict(output='power', method='multitaper', tmin=-0.5, tmax=2.0, fmin=2.0, fmax=200.0, n_jobs=1)\n",
    "freqs = np.arange(2., 201., 2.)\n",
    "n_cycles = freqs / 2.0\n",
    "cfg_timefreq.update(dict(freqs=freqs, n_cycles=n_cycles))\n",
    "\n",
    "# perform TF analysis\n",
    "tfr_epochs = tfr_multitaper(data, **cfg_timefreq)\n",
    "\n",
    "# perform TF baselining\n",
    "tfr_epochs.apply_baseline((-0.25, 0), mode='percent')\n",
    "\n",
    "# define parameters for TF data selection\n",
    "cfg_TFselect = dict(average=True)\n",
    "\n",
    "# PLOT STIM-LOCKED TFs, from 0.5 second before to\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot per channel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import mne\n",
    "\n",
    "# define parameters for TF baselining\n",
    "cfg_TFbl = dict()\n",
    "cfg_TFbl['baseline'] = [-0.25, 0]\n",
    "cfg_TFbl['baselinetype'] = 'db'\n",
    "cfg_TFbl['parameter'] = 'powspctrm'\n",
    "\n",
    "# define parameters for TF data selection\n",
    "cfg_TFselect = dict()\n",
    "cfg_TFselect['avgoverrpt'] = 'yes'\n",
    "\n",
    "# define parameters for TF plotting\n",
    "cfg_TFplot = dict()\n",
    "cfg_TFplot['zlim'] = 'maxabs'\n",
    "cfg_TFplot['interactive'] = 'no'\n",
    "cfg_TFplot['figure'] = 'no'\n",
    "cfg_TFplot['colormap'] = 'jet'\n",
    "\n",
    "catLabel = ['picture naming', 'auditory definition', 'reading completion']\n",
    "\n",
    "for chan in range(len(data.ch_names)):\n",
    "    \n",
    "    # perform TF analysis\n",
    "    cfg_timefreq = dict()\n",
    "    cfg_timefreq['channel'] = data.ch_names[chan]\n",
    "    freq = mne.time_frequency.tfr_morlet(data, **cfg_timefreq)\n",
    "    \n",
    "    # perform TF baselining\n",
    "    freqBL = mne.time_frequency.tfr_baseline(freq, **cfg_TFbl)\n",
    "\n",
    "    # PLOT STIM-LOCKED TFs, from 0.5 second before to 2 seconds after stimulus onset\n",
    "    for ctTask in range(3):\n",
    "\n",
    "        # select trials per task (WITH averaging)\n",
    "        cfg_TFselect['trials'] = trig[:, 4] == ctTask + 1\n",
    "        freq_plot = mne.time_frequency.tfr_morlet(freqBL, **cfg_TFselect)\n",
    "\n",
    "        # do the actual plotting\n",
    "        plt.subplot(3, 2, ctTask*2+1)\n",
    "        cfg_TFplot['figure'] = plt.gcf()\n",
    "        cfg_TFplot['title'] = [freq_plot.ch_names[0] + ' stim: ' + catLabel[ctTask]]\n",
    "        cfg_TFplot['xlim'] = [-0.5, 2]\n",
    "        mne.viz.plot_tfr_single_trial(freq_plot, **cfg_TFplot)\n",
    "\n",
    "        # draw lines for baseline period and stimulus onset\n",
    "        plt.axvline(-0.25, linestyle='--')\n",
    "        plt.axvline(0)\n",
    "\n",
    "    # PLOT RESPONSE-LOCKED TFs, from 1 second before to 2 seconds after response onset\n",
    "    for ctTask in range(3):\n",
    "\n",
    "        # this part realigns individual trials, based on the detection of\n",
    "        # the first NaN (which automatically occurs 3 seconds after the\n",
    "        # \"response\" trigger), which allows to go around the variable\n",
    "        # trial duration\n",
    "\n",
    "        # keep only trials of the current task\n",
    "        freq_tmp = freqBL\n",
    "        freq_tmp.data = freq_tmp.data[trig[:, 4] == ctTask + 1, :, :, :]\n",
    "\n",
    "        # start building re-aligned freq structure\n",
    "        freq_realign = freq_tmp.copy()\n",
    "        freq_realign.data = np.empty((freq_tmp.data.shape[0], freq_tmp.data.shape[1], freq_tmp.data.shape[2], len(np.arange(-1, 2.01, 0.01))))\n",
    "        freq_realign.times = np.arange(-1, 2.01, 0.01)\n",
    "\n",
    "        # do the actual realignment\n",
    "        for ctTrl in range(freq_tmp.data.shape[0]):\n",
    "            # find index of the time point just before the first NaN; this corresponds to 2.75 seconds after response onset\n",
    "            idx_last = np.where\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
